*in progress*

# Data
* [Librispeach](https://www.openslr.org/12/) clean (train 360h, test, dev)
* [Common voice](https://commonvoice.mozilla.org/en/datasets) en (2 681h validated, train, test, dev)

# Resources
* [Challenges and Limitations in Speech Recognition Technology: A Critical Review of Speech Signal Processing Algorithms, Tools and Systems](https://www.sciencedirect.com/org/science/article/pii/S1526149222002880)
* [Audio Emotion Recognition based on Song modality using Conv1D vs Conv2D](http://pe.org.pl/articles/2024/7/12.pdf)
* Docs [Tensorflow](https://www.tensorflow.org/), [librosa](https://librosa.org/doc/latest/index.html)

https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53 \
https://medium.com/towards-data-science/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504 \
https://medium.com/towards-data-science/audio-deep-learning-made-simple-part-2-why-mel-spectrograms-perform-better-aad889a93505 \
https://towardsdatascience.com/audio-deep-learning-made-simple-part-3-data-preparation-and-augmentation-24c6e1f6b52 \
https://medium.com/towards-data-science/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5 \
https://medium.com/towards-data-science/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706