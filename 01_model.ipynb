{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "214a8215-9e6e-41c1-b37e-4c58aff5eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "os.environ[\"TENSORBOARD_BINARY\"] = \".speech_recognition/bin/tensorboard\"\n",
    "\n",
    "# from tensorflow.keras import backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5465ed92-c8f5-408d-ad77-63f5d626ef37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DTypePolicy \"mixed_float16\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.optimizers import LossScaleOptimizer\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "os.makedirs(\"training_images\", exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "log_dir = \"tensorboard/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "char_to_num = {char: idx + 1 for idx, char in enumerate(\"abcdefghijklmnopqrstuvwxyz \")}\n",
    "char_to_num['<PAD>'] = 0\n",
    "num_to_char = {v: k for k, v in char_to_num.items()}\n",
    "n_mfcc = 13\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57764af-6cae-4651-83e9-93d24afd8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_size(dataset_filename: str):\n",
    "    \"\"\"Counts the number of samples in the HDF5 dataset\"\"\"\n",
    "    with h5py.File(f\"data/CommonVoice/{dataset_filename}\", \"r\") as hf:\n",
    "        mfcc_group = hf[\"mfcc\"]\n",
    "        labels_group = hf[\"labels\"]\n",
    "        i = 0\n",
    "        for key in mfcc_group.keys():\n",
    "            i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def dataset_from_generator(h5_file_path):\n",
    "    \"\"\"Returns the generator for the dataset.\"\"\"\n",
    "    \n",
    "    def generator():\n",
    "        \n",
    "        with h5py.File(h5_file_path, \"r\") as hf:\n",
    "            mfcc_group = hf[\"mfcc\"]\n",
    "            labels_group = hf[\"labels\"]\n",
    "            \n",
    "            for key in mfcc_group.keys():\n",
    "                mfcc = mfcc_group[key][:]\n",
    "                labels = labels_group[key][:]\n",
    "                \n",
    "                yield mfcc, labels\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 13), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "        ))\n",
    "\n",
    "\n",
    "def generate_padded_data(h5_file_path, batch_size=32):\n",
    "    \"\"\"Performs padding in batches.\"\"\"\n",
    "    dataset = dataset_from_generator(h5_file_path)\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size=batch_size,\n",
    "        padded_shapes=(\n",
    "            [None, 13],\n",
    "            [None]\n",
    "        ),\n",
    "        padding_values=(\n",
    "            0.0,\n",
    "            char_to_num['<PAD>']\n",
    "        ))\n",
    "    \n",
    "    # return dataset.repeat().prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def plot_loss_curves(history, model_name):\n",
    "    \"\"\"Return separate loss curves for training and validation results.\"\"\"\n",
    "    \n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(epochs, loss, label=\"training loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"val loss\")\n",
    "    plt.title(f\"CTC loss for {model_name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"training_images/{model_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def build_model(model_name, layer_list, input_shape=(None, 13), vocab_size=len(char_to_num), learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Creates a model from a list of layers using keras functional api; input and output is permanently defined.\n",
    "    The returned model is compiled using CTC and Loss scale optimizer.\n",
    "    \"\"\"\n",
    "        \n",
    "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    x = inputs\n",
    "    for layer in layer_list:\n",
    "        x = layer(x)\n",
    "\n",
    "    outputs = layers.Dense(units=vocab_size, name=\"output_layer\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=model_name)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=learning_rate)),\n",
    "        loss=tf.keras.losses.CTC())\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                train_data,\n",
    "                val_data,\n",
    "                train_data_size,\n",
    "                val_data_size,\n",
    "                batch_size=32,\n",
    "                epochs=20,\n",
    "                initial_epoch=0,\n",
    "                callbacks=None):\n",
    "    \"Trains model, plots and returns history.\"\n",
    "    \n",
    "    history = model.fit(\n",
    "                train_data,\n",
    "                validation_data=val_data,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=int(train_data_size/batch_size),\n",
    "                validation_steps=int(val_data_size/batch_size),\n",
    "                callbacks=callbacks,\n",
    "                verbose=1,\n",
    "                initial_epoch=initial_epoch\n",
    "                )\n",
    "    \n",
    "    plot_loss_curves(history, model.name)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def decode(sequence, pred=True):\n",
    "    \"\"\"Decodes labels and predictions.\"\"\"\n",
    "    if pred:\n",
    "        sequence = tf.argmax(sequence, axis=-1)\n",
    "    sequence = tf.reshape(sequence, [-1])\n",
    "    decoded = []\n",
    "    for idx in sequence.numpy():\n",
    "        char = num_to_char.get(idx, '')\n",
    "        if char != '<PAD>':\n",
    "            decoded.append(char)\n",
    "    decoded = \"\".join(decoded)\n",
    "\n",
    "    return \" \".join(decoded.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cec0a7-5266-46bd-bc64-991d8de7e961",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "## CTC - Connectionist Temporal Classification\n",
    "* Enables comparative analysis of sequences with different lengths, where there is no clear alignment between input and output, e.g., audio and transcription.\n",
    "* Predictions are in the form of logits, blank index - 0; no additional function is used in the output layer.\n",
    "* Loss value is normalized by default at the batch level - allows comparison of batches with samples of varying sizes.\n",
    "\n",
    "# Types of Networks\n",
    "* LSTM and GRU, unidirectional and bidirectional.\n",
    "* 1D and 2D convolutional networks.\n",
    "\n",
    "# Padding\n",
    "Adding special values (usually zeros) to data sequences to align them to the same length, allowing the processing of data of varying sizes in models that require fixed-length input. The data is loaded from the shortest to the longest sequences to reduce padding, which occurs within batches. Afterward, the dataset is sorted at the batch level.\n",
    "\n",
    "# Mixed Precision\n",
    "* Using different precisions (e.g., 16-bit and 32-bit) to speed up computations and reduce memory usage.\n",
    "* LossScaleOptimizer - a technique to scale the loss to prevent precision loss when calculating gradients in mixed precision. It involves multiplying the loss value by a constant (called the scale factor) and then, after computing the gradients, dividing them by the same factor. This helps avoid the issue of very small gradients, which can lead to instability during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4544e8-aaf8-45c1-b77e-d9464047e8cd",
   "metadata": {},
   "source": [
    "# Loading dataset from generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2eacac-490c-4212-8fd6-64c36505a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 45161, Val: 5018, Test: 25090\n"
     ]
    }
   ],
   "source": [
    "train_data_size = check_dataset_size(\"train.h5\")\n",
    "train_dataset = generate_padded_data(\"data/CommonVoice/train.h5\").shuffle(buffer_size=train_data_size, seed=42).take(int(train_data_size/2)).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = generate_padded_data(\"data/CommonVoice/test.h5\").repeat().prefetch(tf.data.AUTOTUNE)\n",
    "test_data_size = check_dataset_size(\"test.h5\")\n",
    "\n",
    "val_data_size = check_dataset_size(\"val.h5\")\n",
    "val_dataset = generate_padded_data(\"data/CommonVoice/val.h5\").shuffle(buffer_size=val_data_size, seed=42).take(int(val_data_size/2)).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Train: {int(train_data_size/2)}, Val: {int(val_data_size/2)}, Test: {test_data_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77035e93-eefb-4c37-9110-7f3d76a6e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 288, 13) (32, 101)\n",
      "(32, 313, 13) (32, 87)\n",
      "(32, 331, 13) (32, 89)\n",
      "(32, 275, 13) (32, 92)\n",
      "(32, 294, 13) (32, 98)\n"
     ]
    }
   ],
   "source": [
    "for d, l in train_dataset.take(5):\n",
    "    print(d.shape, l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395b940-edf7-4608-8c28-febff17db19b",
   "metadata": {},
   "source": [
    "# 1/2 of data for faster prototyping model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbc994c-5842-49fd-93a2-fd5106066b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 13)\n",
    "dropout = 0.2\n",
    "\n",
    "models = {\n",
    "    \"BLSTM\": [\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "    ],\n",
    "    \"BGRU\": [\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "    ],\n",
    "    \"CNN1D_BGRU\": [\n",
    "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "    ],\n",
    "    \"CNN1D_BLSTM\": [\n",
    "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "    ],\n",
    "    \"CNN2D_BLSTM\": [\n",
    "        layers.Reshape((-1, input_shape[1], 1)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.TimeDistributed(layers.Flatten()),\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=dropout)),\n",
    "    ],\n",
    "    \"CNN2D_BGRU\": [\n",
    "        layers.Reshape((-1, input_shape[1], 1)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.TimeDistributed(layers.Flatten()),\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "        layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=dropout)),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "all_results = []\n",
    "    \n",
    "for name, layer_list in models.items():  \n",
    "    model = build_model(name, layer_list)\n",
    "    print(f\"Training model {name}....\")\n",
    "    # print(model.summary())\n",
    "\n",
    "    experiment_dir = f\"{log_dir}50%/{name}\"\n",
    "\n",
    "    callbacks = [\n",
    "    ModelCheckpoint(f\"checkpoints/{name}.ckpt.weights.h5\",\n",
    "                   # save_best_only=True,\n",
    "                   save_weights_only=True),\n",
    "    EarlyStopping(patience=3,\n",
    "                  restore_best_weights=True),\n",
    "    TensorBoard(log_dir=experiment_dir,\n",
    "                histogram_freq=1,\n",
    "                write_steps_per_second=True)\n",
    "    ]\n",
    "    \n",
    "    history = train_model(model, train_dataset, val_dataset,\n",
    "                          callbacks=callbacks,\n",
    "                          train_data_size=train_data_size/2,\n",
    "                          val_data_size=val_data_size/2,\n",
    "                          epochs=10)\n",
    "\n",
    "    results = {\n",
    "        \"Model\": name,\n",
    "        \"Params\": model.count_params(),\n",
    "        \"Train loss\": history.history[\"loss\"][-1],\n",
    "        \"Val loss\": history.history[\"val_loss\"][-1],\n",
    "        \"Test loss\": model.evaluate(test_dataset, verbose=0, steps=test_data_size//32)\n",
    "    }\n",
    "    all_results.append(results)\n",
    "\n",
    "all_results = pd.DataFrame(all_results)\n",
    "all_results.to_csv(\"50%_data_results.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c9c2818-4c5d-4a73-8d00-4537800673f3",
   "metadata": {},
   "source": [
    "Primarily recurrent networks can be used to analyze MFCC data, but convolutional networks (both 1D and 2D) can also work well.\n",
    "\n",
    "In this case, it seems that although convolutional networks greatly accelerated the training of the model, the information was reduced too much.\n",
    "\n",
    "Moreover, the more complex LSTMs perform better than their simplified version, GRU, so LSTMs will be used in further tests.\n",
    "\n",
    "![image.png](images/tensorboard_initial.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a542a9-255a-45aa-87ea-24a3d07fc2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b7bee_row0_col1 {\n",
       "  background-color: #97b7d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b7bee_row0_col2, #T_b7bee_row0_col3, #T_b7bee_row0_col4, #T_b7bee_row1_col1 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b7bee_row1_col2, #T_b7bee_row1_col3, #T_b7bee_row1_col4 {\n",
       "  background-color: #f2ecf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b7bee_row2_col1 {\n",
       "  background-color: #f5eff6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b7bee_row2_col2, #T_b7bee_row2_col4, #T_b7bee_row4_col1, #T_b7bee_row5_col3 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row2_col3, #T_b7bee_row5_col2 {\n",
       "  background-color: #023c5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row3_col1 {\n",
       "  background-color: #76aad0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row3_col2, #T_b7bee_row4_col3, #T_b7bee_row4_col4 {\n",
       "  background-color: #04588a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row3_col3 {\n",
       "  background-color: #034d79;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row3_col4 {\n",
       "  background-color: #046198;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row4_col2 {\n",
       "  background-color: #045687;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b7bee_row5_col1 {\n",
       "  background-color: #8bb2d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b7bee_row5_col4 {\n",
       "  background-color: #02395a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b7bee\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b7bee_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b7bee_level0_col1\" class=\"col_heading level0 col1\" >Params</th>\n",
       "      <th id=\"T_b7bee_level0_col2\" class=\"col_heading level0 col2\" >Train loss</th>\n",
       "      <th id=\"T_b7bee_level0_col3\" class=\"col_heading level0 col3\" >Val loss</th>\n",
       "      <th id=\"T_b7bee_level0_col4\" class=\"col_heading level0 col4\" >Test loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b7bee_row0_col0\" class=\"data row0 col0\" >BLSTM</td>\n",
       "      <td id=\"T_b7bee_row0_col1\" class=\"data row0 col1\" >2142236</td>\n",
       "      <td id=\"T_b7bee_row0_col2\" class=\"data row0 col2\" >72.45</td>\n",
       "      <td id=\"T_b7bee_row0_col3\" class=\"data row0 col3\" >70.84</td>\n",
       "      <td id=\"T_b7bee_row0_col4\" class=\"data row0 col4\" >70.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b7bee_row1_col0\" class=\"data row1 col0\" >BGRU</td>\n",
       "      <td id=\"T_b7bee_row1_col1\" class=\"data row1 col1\" >1613340</td>\n",
       "      <td id=\"T_b7bee_row1_col2\" class=\"data row1 col2\" >78.25</td>\n",
       "      <td id=\"T_b7bee_row1_col3\" class=\"data row1 col3\" >76.93</td>\n",
       "      <td id=\"T_b7bee_row1_col4\" class=\"data row1 col4\" >77.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b7bee_row2_col0\" class=\"data row2 col0\" >CNN1D_BGRU</td>\n",
       "      <td id=\"T_b7bee_row2_col1\" class=\"data row2 col1\" >1694236</td>\n",
       "      <td id=\"T_b7bee_row2_col2\" class=\"data row2 col2\" >141.15</td>\n",
       "      <td id=\"T_b7bee_row2_col3\" class=\"data row2 col3\" >138.84</td>\n",
       "      <td id=\"T_b7bee_row2_col4\" class=\"data row2 col4\" >139.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b7bee_row3_col0\" class=\"data row3 col0\" >CNN1D_BLSTM</td>\n",
       "      <td id=\"T_b7bee_row3_col1\" class=\"data row3 col1\" >2249244</td>\n",
       "      <td id=\"T_b7bee_row3_col2\" class=\"data row3 col2\" >132.98</td>\n",
       "      <td id=\"T_b7bee_row3_col3\" class=\"data row3 col3\" >134.68</td>\n",
       "      <td id=\"T_b7bee_row3_col4\" class=\"data row3 col4\" >128.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b7bee_row4_col0\" class=\"data row4 col0\" >CNN2D_BLSTM</td>\n",
       "      <td id=\"T_b7bee_row4_col1\" class=\"data row4 col1\" >2902684</td>\n",
       "      <td id=\"T_b7bee_row4_col2\" class=\"data row4 col2\" >133.50</td>\n",
       "      <td id=\"T_b7bee_row4_col3\" class=\"data row4 col3\" >132.02</td>\n",
       "      <td id=\"T_b7bee_row4_col4\" class=\"data row4 col4\" >131.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7bee_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b7bee_row5_col0\" class=\"data row5 col0\" >CNN2D_BGRU</td>\n",
       "      <td id=\"T_b7bee_row5_col1\" class=\"data row5 col1\" >2183836</td>\n",
       "      <td id=\"T_b7bee_row5_col2\" class=\"data row5 col2\" >139.89</td>\n",
       "      <td id=\"T_b7bee_row5_col3\" class=\"data row5 col3\" >140.15</td>\n",
       "      <td id=\"T_b7bee_row5_col4\" class=\"data row5 col4\" >139.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d8ceabff500>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"50%_data_results.csv\")\n",
    "results.style.background_gradient(subset=df.columns[1:]).format(subset=df.columns[2:], formatter=\"{:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1828484-a3d4-42f0-ba45-453e6a06b750",
   "metadata": {},
   "source": [
    "## Predictions \n",
    "\n",
    "### In the form of RaggedTensor\n",
    "* Allows storing data of varying sizes.\n",
    "* Probabilities of each character at every time step are represented as logits.\n",
    "\n",
    "![image.png](images/rag_tens.png)\n",
    "\n",
    "### Checking decoded predictions\n",
    "Of course, at this stage they are far from good, but nevertheless phonetically it is not so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "928bd54c-6fb4-4f5a-877b-26f0a1739ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"BLSTM\"\n",
    "layers_list =  models[name]\n",
    "model = build_model(name, layer_list=layers_list, learning_rate=1e-03)\n",
    "model.load_weights(f\"checkpoints/{name}.ckpt.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae47be10-a6c8-49a4-bf81-af6c71b3c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: pachman went on to become one of the worlds leading players\n",
      "Pred: tastbenn onnhn the becoomm int a orrll llaavein playyerrss\n",
      "\n",
      "True: he emigrated from england to pennsylvania where he married elizabeth welding\n",
      "Pred: hhhe inrraated from gulinse to esomaa weere e arrry eliss bitth wwellli\n",
      "\n",
      "True: other record companies rejected them seeing a potential only in rosendahl\n",
      "Pred: otther rrecorrdd companneess rrrejecctted toum senng of heeteenntiiall unly an rrossann all\n",
      "\n",
      "True: any party faction or politician may be labeled green if it emphasizes environmental causes\n",
      "Pred: aporrrry raon worrrk ollobsittioonn anella pogrrren ia omm pesisess nn vorrmerntto n consess\n",
      "\n",
      "True: he joined brown university as a coach\n",
      "Pred: he joinn drronn inn vessity aass a cootn\n",
      "\n",
      "True: sherriff also wrote prose\n",
      "Pred: sshervff allssso ro prrillss\n",
      "\n",
      "True: medieval moscow grew from its kremlin primarily in a northeasterly direction towards the yauza\n",
      "Pred: the dival lossko grrffermencs cillln prevarrrilly ann a ortteessstor the dorecttioonn t worrss beyeza\n",
      "\n",
      "True: content developers may also be search engine optimization specialists or internet marketing professionals\n",
      "Pred: comtentt olverrsslmiye allsso besireh endiinn ofhpersastiionsssocaalttss for interrnnn orprinn oofsional\n",
      "\n",
      "True: he played various famous grandmasters\n",
      "Pred: hhe pllayye vherrriiiass fannauss grrann ammmasstorrss\n",
      "\n",
      "True: she also teaches dance classes to young children at her mothers dance studio\n",
      "Pred: shhe alllsso caaatiionss anspesstes ttooallnntthollde aootheerrss danttogoa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for data, label in test_dataset.rebatch(1).take(10):\n",
    "    labels.append(label)\n",
    "    pred = model.predict(data, verbose=False)\n",
    "    predictions.append(pred)\n",
    "\n",
    "decoded_labels = []\n",
    "decoded_preds = []\n",
    "\n",
    "for l, p in zip(labels, predictions):\n",
    "    decoded_labels.append(decode(l, pred=False))\n",
    "    decoded_preds.append(decode(p, pred=True))\n",
    "\n",
    "for true_label, pred in zip(decoded_labels, decoded_preds):\n",
    "    print(f\"True: {true_label}\")\n",
    "    print(f\"Pred: {pred}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcfd18-de55-4309-aeab-efbd4686fa08",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "For the record â€“ they will be terrible for now.\n",
    "\n",
    "## CER - Character Error Rate\n",
    "The ratio of incorrect characters in the predicted transcription to the total number of characters in the true transcription.\n",
    "\n",
    "## WER - Word Error Rate\n",
    "The ratio of incorrect words in the predicted transcription to the total number of words in the true transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64617d65-f198-4afb-91a4-853c0a900cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CER: 0.51\n",
      "Average WER: 0.98\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "cer_values = [jiwer.cer(label, pred) for label, pred in zip(decoded_labels, decoded_preds)]\n",
    "wer_values = [jiwer.wer(label, pred) for label, pred in zip(decoded_labels, decoded_preds)]\n",
    "average_cer = sum(cer_values) / len(cer_values)\n",
    "average_wer = sum(wer_values) / len(wer_values)\n",
    "\n",
    "print(f\"Average CER: {round(average_cer, 2)}\")\n",
    "print(f\"Average WER: {round(average_wer, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_recognition",
   "language": "python",
   "name": "speech_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
